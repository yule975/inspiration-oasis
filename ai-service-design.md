# çµæ„Ÿç»¿æ´² - AIæœåŠ¡è®¾è®¡æ–¹æ¡ˆ
## åŸºäº OpenRouter API é›†æˆ

### ğŸ¯ OpenRouter ç®€ä»‹
OpenRouter æ˜¯ä¸€ä¸ªAIæ¨¡å‹è·¯ç”±æœåŠ¡ï¼Œæä¾›ç»Ÿä¸€APIè®¿é—®å¤šç§ä¸»æµAIæ¨¡å‹ï¼š
- **GPTç³»åˆ—**: GPT-4, GPT-3.5-turbo
- **Anthropic**: Claude-3-opus, Claude-3-sonnet, Claude-3-haiku  
- **Google**: Gemini-pro
- **å¼€æºæ¨¡å‹**: Llama-2, Mistralç­‰

### ğŸ”§ æŠ€æœ¯æ¶æ„è®¾è®¡

#### 1. AIæœåŠ¡å±‚æ¶æ„
```
å‰ç«¯è¯·æ±‚ â†’ åç«¯API â†’ AIæœåŠ¡ä¸­é—´å±‚ â†’ OpenRouter API â†’ AIæ¨¡å‹ â†’ å“åº”é“¾è·¯
```

#### 2. æ ¸å¿ƒç»„ä»¶è®¾è®¡

**AI Service Manager (AIæœåŠ¡ç®¡ç†å™¨)**
```javascript
class AIServiceManager {
  constructor() {
    this.openRouterApiKey = process.env.OPENROUTER_API_KEY
    this.defaultModel = "openai/gpt-3.5-turbo"  // é»˜è®¤æ¨¡å‹
    this.baseURL = "https://openrouter.ai/api/v1"
  }
  
  // æ¨¡å‹é€‰æ‹©ç­–ç•¥
  selectModel(taskType, complexity = 'normal') {
    const modelMap = {
      'enhance': {
        simple: 'openai/gpt-3.5-turbo',      // å†…å®¹ä¼˜åŒ–
        complex: 'openai/gpt-4'              // å¤æ‚å¢å¼º
      },
      'summarize': {
        simple: 'anthropic/claude-3-haiku',   // å¿«é€Ÿæ€»ç»“
        complex: 'anthropic/claude-3-sonnet'  // æ·±åº¦åˆ†æ
      },
      'chat': {
        simple: 'openai/gpt-3.5-turbo',
        complex: 'anthropic/claude-3-opus'    // æ·±åº¦å¯¹è¯
      },
      'tags': {
        simple: 'openai/gpt-3.5-turbo',      // æ ‡ç­¾æ¨è
        complex: 'openai/gpt-3.5-turbo'
      },
      'analyze': {
        simple: 'anthropic/claude-3-sonnet',  // è¶‹åŠ¿åˆ†æ
        complex: 'openai/gpt-4'
      }
    }
    
    return modelMap[taskType]?.[complexity] || this.defaultModel
  }
}
```

#### 3. å…·ä½“åŠŸèƒ½å®ç°

##### A. å†…å®¹å¢å¼ºæœåŠ¡
```javascript
// POST /api/ai/enhance
async function enhanceContent(content, type, context) {
  const model = aiService.selectModel('enhance', 
    content.length > 500 ? 'complex' : 'simple'
  )
  
  const prompts = {
    optimize: `è¯·ä¼˜åŒ–ä»¥ä¸‹å†…å®¹çš„è¡¨è¾¾ï¼Œä½¿å…¶æ›´åŠ æ¸…æ™°å‡†ç¡®ï¼š\n\n${content}`,
    expand: `è¯·æ‰©å±•ä»¥ä¸‹æƒ³æ³•ï¼Œæä¾›æ›´å¤šç»†èŠ‚å’Œåº”ç”¨åœºæ™¯ï¼š\n\n${content}`,
    tone: `è¯·æ¶¦è‰²ä»¥ä¸‹å†…å®¹çš„è¯­æ°”ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šå’Œå‹å¥½ï¼š\n\n${content}`
  }
  
  const response = await openRouterRequest({
    model: model,
    messages: [
      {
        role: "system", 
        content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹ç¼–è¾‘åŠ©æ‰‹ï¼Œæ“…é•¿ä¼˜åŒ–å’Œæ”¹è¿›æ–‡æœ¬å†…å®¹ã€‚"
      },
      {
        role: "user", 
        content: prompts[type]
      }
    ],
    max_tokens: 1000,
    temperature: 0.7
  })
  
  return {
    original_content: content,
    enhanced_content: response.choices[0].message.content,
    enhancement_type: type,
    model_used: model,
    suggestions: await generateSuggestions(content, type)
  }
}
```

##### B. æ™ºèƒ½æ€»ç»“æœåŠ¡
```javascript
// POST /api/ai/summarize  
async function summarizeContent(content, summaryType = 'brief') {
  const model = aiService.selectModel('summarize', 
    summaryType === 'detailed' ? 'complex' : 'simple'
  )
  
  const systemPrompts = {
    brief: "æä¾›ç®€æ´çš„æ ¸å¿ƒè§‚ç‚¹æ€»ç»“",
    detailed: "æä¾›è¯¦ç»†çš„åˆ†ææ€»ç»“ï¼ŒåŒ…å«å…³é”®è¦ç‚¹å’Œæ´å¯Ÿ",
    key_points: "æå–3-5ä¸ªå…³é”®è¦ç‚¹ï¼Œä»¥åˆ—è¡¨å½¢å¼å‘ˆç°"
  }
  
  const response = await openRouterRequest({
    model: model,
    messages: [
      {
        role: "system",
        content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æå¸ˆã€‚${systemPrompts[summaryType]}`
      },
      {
        role: "user",
        content: `è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š\n\n${content}`
      }
    ],
    max_tokens: 800,
    temperature: 0.3
  })
  
  // å¹¶è¡Œæå–å…³é”®ç‚¹å’Œæ´å¯Ÿ
  const [keyPoints, insights] = await Promise.all([
    extractKeyPoints(content),
    generateInsights(content)
  ])
  
  return {
    summary: response.choices[0].message.content,
    key_points: keyPoints,
    insights: insights,
    model_used: model
  }
}
```

##### C. AIå¯¹è¯æœåŠ¡
```javascript
// POST /api/ai/chat
async function chatWithAI(message, context, conversationId) {
  const model = aiService.selectModel('chat', 
    message.length > 200 ? 'complex' : 'simple'
  )
  
  // è·å–å¯¹è¯å†å²
  const conversation = await getConversationHistory(conversationId)
  
  const messages = [
    {
      role: "system",
      content: `ä½ æ˜¯çµæ„Ÿç»¿æ´²çš„AIåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·æ·±å…¥åˆ†æåˆ›æ„æƒ³æ³•ã€‚
      å½“å‰è®¨è®ºä¸Šä¸‹æ–‡ï¼š${context}
      
      è¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ–¹å¼å›åº”ç”¨æˆ·ï¼Œæä¾›å»ºè®¾æ€§çš„å»ºè®®å’Œæ·±å…¥çš„åˆ†æã€‚`
    },
    ...conversation.messages,  // å†å²å¯¹è¯
    {
      role: "user",
      content: message
    }
  ]
  
  const response = await openRouterRequest({
    model: model,
    messages: messages,
    max_tokens: 1200,
    temperature: 0.8
  })
  
  // ç”Ÿæˆåç»­é—®é¢˜å»ºè®®
  const suggestions = await generateFollowUpQuestions(message, context)
  
  // ä¿å­˜å¯¹è¯å†å²
  await saveConversationMessage(conversationId, {
    user: message,
    assistant: response.choices[0].message.content
  })
  
  return {
    reply: response.choices[0].message.content,
    conversation_id: conversationId,
    suggestions: suggestions,
    model_used: model
  }
}
```

##### D. æ ‡ç­¾æ¨èæœåŠ¡
```javascript
// POST /api/ai/tags/suggest
async function suggestTags(content, maxTags = 5) {
  const model = aiService.selectModel('tags', 'simple')
  
  const response = await openRouterRequest({
    model: model,
    messages: [
      {
        role: "system",
        content: `ä½ æ˜¯ä¸€ä¸ªæ ‡ç­¾æ¨èä¸“å®¶ã€‚æ ¹æ®å†…å®¹æ¨è${maxTags}ä¸ªæœ€ç›¸å…³çš„æ ‡ç­¾ã€‚
        æ ‡ç­¾åº”è¯¥ï¼š
        1. å‡†ç¡®åæ˜ å†…å®¹ä¸»é¢˜
        2. æœ‰åŠ©äºå†…å®¹åˆ†ç±»å’Œæœç´¢
        3. ä½¿ç”¨å¸¸è§çš„æŠ€æœ¯å’Œè¡Œä¸šæœ¯è¯­
        
        åªè¿”å›JSONæ ¼å¼ï¼š{"tags": [{"tag": "æ ‡ç­¾å", "confidence": 0.95, "reason": "æ¨èç†ç”±"}]}`
      },
      {
        role: "user",
        content: `è¯·ä¸ºä»¥ä¸‹å†…å®¹æ¨èæ ‡ç­¾ï¼š\n\n${content}`
      }
    ],
    max_tokens: 500,
    temperature: 0.3
  })
  
  try {
    const result = JSON.parse(response.choices[0].message.content)
    return {
      suggested_tags: result.tags.slice(0, maxTags),
      model_used: model
    }
  } catch (error) {
    // é™çº§å¤„ç†ï¼šä½¿ç”¨å…³é”®è¯æå–
    return await fallbackTagExtraction(content, maxTags)
  }
}
```

##### E. æ¯æ—¥ç®€æŠ¥ç”Ÿæˆ
```javascript
// GET /api/ai/brief/daily
async function generateDailyBrief(date, categories) {
  const model = aiService.selectModel('analyze', 'complex')
  
  // è·å–å½“æ—¥ç›¸å…³æ–°é—»å’Œè¶‹åŠ¿æ•°æ®
  const [newsData, trendsData] = await Promise.all([
    fetchNewsData(date, categories),
    fetchTrendsData(date)
  ])
  
  const response = await openRouterRequest({
    model: model,
    messages: [
      {
        role: "system",
        content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æŠ€èµ„è®¯åˆ†æå¸ˆã€‚åŸºäºæä¾›çš„æ–°é—»å’Œè¶‹åŠ¿æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´æœ‰ä»·å€¼çš„æ¯æ—¥ç®€æŠ¥ã€‚
        
        ç®€æŠ¥åº”åŒ…å«ï¼š
        1. å½“æ—¥è¦é—»æ€»ç»“ï¼ˆ2-3å¥ï¼‰
        2. 3-5æ¡é‡è¦æ–°é—»ï¼Œæ¯æ¡åŒ…å«æ ‡é¢˜ã€æ‘˜è¦ã€æ ‡ç­¾ã€é‡è¦ç¨‹åº¦
        3. è¶‹åŠ¿æ´å¯Ÿå’Œå»ºè®®
        
        ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚`
      },
      {
        role: "user",
        content: `è¯·åŸºäºä»¥ä¸‹æ•°æ®ç”Ÿæˆ${date}çš„AIç®€æŠ¥ï¼š
        
        æ–°é—»æ•°æ®ï¼š${JSON.stringify(newsData)}
        è¶‹åŠ¿æ•°æ®ï¼š${JSON.stringify(trendsData)}`
      }
    ],
    max_tokens: 2000,
    temperature: 0.4
  })
  
  return parseAIBriefResponse(response.choices[0].message.content)
}
```

### ğŸ” OpenRouter é›†æˆé…ç½®

#### 1. ç¯å¢ƒå˜é‡é…ç½®
```env
# OpenRouter APIé…ç½®
OPENROUTER_API_KEY=your_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_APP_NAME=çµæ„Ÿç»¿æ´²
OPENROUTER_APP_URL=https://inspiration-oasis.com

# æ¨¡å‹é…ç½®
DEFAULT_CHAT_MODEL=openai/gpt-3.5-turbo
DEFAULT_ANALYZE_MODEL=anthropic/claude-3-sonnet
DEFAULT_ENHANCE_MODEL=openai/gpt-3.5-turbo

# é™åˆ¶é…ç½®
MAX_TOKENS_PER_REQUEST=2000
RATE_LIMIT_PER_MINUTE=60
```

#### 2. è¯·æ±‚å°è£…å‡½æ•°
```javascript
async function openRouterRequest(payload) {
  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
      'HTTP-Referer': process.env.OPENROUTER_APP_URL,
      'X-Title': process.env.OPENROUTER_APP_NAME,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(payload)
  })
  
  if (!response.ok) {
    throw new AIServiceError(`OpenRouter API error: ${response.status}`)
  }
  
  return await response.json()
}
```

### ğŸ’° æˆæœ¬ä¼˜åŒ–ç­–ç•¥

#### 1. æ¨¡å‹é€‰æ‹©ç­–ç•¥
```javascript
const MODEL_COSTS = {
  'openai/gpt-3.5-turbo': { input: 0.001, output: 0.002 },    // ä½æˆæœ¬
  'openai/gpt-4': { input: 0.03, output: 0.06 },             // é«˜è´¨é‡
  'anthropic/claude-3-haiku': { input: 0.00025, output: 0.00125 }, // æä½æˆæœ¬
  'anthropic/claude-3-sonnet': { input: 0.003, output: 0.015 },    // å¹³è¡¡
  'anthropic/claude-3-opus': { input: 0.015, output: 0.075 }       // æœ€é«˜è´¨é‡
}

function selectCostEffectiveModel(taskType, contentLength, userTier) {
  // æ ¹æ®ä»»åŠ¡ç±»å‹ã€å†…å®¹é•¿åº¦å’Œç”¨æˆ·ç­‰çº§é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹
  if (userTier === 'free' && contentLength < 500) {
    return 'anthropic/claude-3-haiku'  // å…è´¹ç”¨æˆ·ä½¿ç”¨ä½æˆæœ¬æ¨¡å‹
  }
  
  if (taskType === 'enhance' && contentLength < 200) {
    return 'openai/gpt-3.5-turbo'  // ç®€å•å¢å¼ºä»»åŠ¡
  }
  
  return getDefaultModelForTask(taskType)
}
```

#### 2. ç¼“å­˜æœºåˆ¶
```javascript
// å¯¹ç›¸ä¼¼è¯·æ±‚è¿›è¡Œç¼“å­˜ï¼Œå‡å°‘APIè°ƒç”¨
const aiCache = new Map()

async function getCachedAIResponse(cacheKey, requestFn) {
  if (aiCache.has(cacheKey)) {
    return aiCache.get(cacheKey)
  }
  
  const response = await requestFn()
  aiCache.set(cacheKey, response)
  
  // è®¾ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´
  setTimeout(() => aiCache.delete(cacheKey), 3600000) // 1å°æ—¶
  
  return response
}
```

### ğŸ“Š é”™è¯¯å¤„ç†å’Œç›‘æ§

#### 1. é”™è¯¯å¤„ç†
```javascript
class AIServiceError extends Error {
  constructor(message, code, details) {
    super(message)
    this.code = code
    this.details = details
  }
}

async function handleAIRequest(requestFn, fallbackFn = null) {
  try {
    return await requestFn()
  } catch (error) {
    // è®°å½•é”™è¯¯
    console.error('AI Service Error:', error)
    
    // å¦‚æœæœ‰é™çº§æ–¹æ¡ˆï¼Œæ‰§è¡Œé™çº§
    if (fallbackFn) {
      return await fallbackFn()
    }
    
    throw new AIServiceError(
      'AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•',
      'AI_SERVICE_UNAVAILABLE',
      error.message
    )
  }
}
```

#### 2. ä½¿ç”¨æƒ…å†µç›‘æ§
```javascript
// ç›‘æ§AIæœåŠ¡ä½¿ç”¨æƒ…å†µ
const aiMetrics = {
  requestCount: 0,
  tokenUsage: 0,
  errorCount: 0,
  averageResponseTime: 0
}

function trackAIUsage(model, inputTokens, outputTokens, responseTime) {
  aiMetrics.requestCount++
  aiMetrics.tokenUsage += inputTokens + outputTokens
  aiMetrics.averageResponseTime = 
    (aiMetrics.averageResponseTime * (aiMetrics.requestCount - 1) + responseTime) / aiMetrics.requestCount
  
  // è®°å½•åˆ°æ•°æ®åº“æˆ–æ—¥å¿—ç³»ç»Ÿ
  logAIUsage({ model, inputTokens, outputTokens, responseTime })
}
```

### ğŸš€ å®æ–½è®¡åˆ’

#### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€é›†æˆ (1å‘¨)
- [x] è®¾ç½®OpenRouter APIé›†æˆ
- [ ] å®ç°åŸºç¡€çš„å†…å®¹å¢å¼ºåŠŸèƒ½
- [ ] å®ç°ç®€å•çš„æ ‡ç­¾æ¨è
- [ ] åŸºç¡€é”™è¯¯å¤„ç†

#### ç¬¬äºŒé˜¶æ®µï¼šæ ¸å¿ƒåŠŸèƒ½ (2å‘¨)  
- [ ] æ™ºèƒ½æ€»ç»“æœåŠ¡
- [ ] AIå¯¹è¯åŠŸèƒ½
- [ ] æ¯æ—¥ç®€æŠ¥ç”Ÿæˆ
- [ ] ç¼“å­˜æœºåˆ¶å®ç°

#### ç¬¬ä¸‰é˜¶æ®µï¼šä¼˜åŒ–å®Œå–„ (1å‘¨)
- [ ] æˆæœ¬ä¼˜åŒ–ç­–ç•¥
- [ ] æ€§èƒ½ç›‘æ§
- [ ] é™çº§å¤„ç†æ–¹æ¡ˆ
- [ ] ç”¨æˆ·é™åˆ¶å’Œè®¡è´¹

è¿™ä¸ªè®¾è®¡æ–¹æ¡ˆå¯ä»¥å……åˆ†åˆ©ç”¨OpenRouterçš„å¤šæ¨¡å‹ä¼˜åŠ¿ï¼Œæ ¹æ®ä¸åŒä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ï¼Œåœ¨ä¿è¯åŠŸèƒ½çš„åŒæ—¶æ§åˆ¶æˆæœ¬ã€‚æ‚¨è§‰å¾—è¿™ä¸ªæ–¹æ¡ˆå¦‚ä½•ï¼Ÿ
